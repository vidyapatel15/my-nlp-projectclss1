{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3ca0fb38",
      "metadata": {
        "id": "3ca0fb38"
      },
      "source": [
        "#Week 1. NLP Basics with NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5543f13",
      "metadata": {
        "id": "c5543f13"
      },
      "source": [
        "## 1. What is NLTK?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42026db7",
      "metadata": {
        "id": "42026db7"
      },
      "source": [
        "NLTK (Natural Language Toolkit) is one of the most important and also the earliest Python-based NLP development tool. NLTK is developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania.\n",
        "\n",
        "In summary, NLTK provides convenience interface with over 50 corpora and lexical resources such as WordNet - WordNet® is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept and also one of the most im-portant the fundamental lexical database in NLP world, developed by Princeton University from 1980's.\n",
        "Other lexical databases and corpora such as the Penn Treebank Corpus, Open Multilingual Wordnet, Problem Report Corpus, and Lin’s Dependency Thesaurus.\n",
        "\n",
        "In fact, the most important feature of NLTK is that it contains the basic statisti-cal-based text processing libraries for FIVE fundamental NLP enabling technolo-gy together with basic semantic reasoning tool, which include:\n",
        "- tokenization\n",
        "- parsing\n",
        "- classification\n",
        "- stemming\n",
        "- tagging\n",
        "- basic semantic reasoning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5189319b-e6f8-4bfc-bbe7-7b006c6d5131",
      "metadata": {
        "id": "5189319b-e6f8-4bfc-bbe7-7b006c6d5131"
      },
      "source": [
        "In this workshop, the demostration with all workshops use python 3.11.9 as running environment. We strongly recommend yours can build a independent virtual environment for these workshops of the book. With any version of pre-installed Anaconda, ths command is:\n",
        "### conda create -n *your_virtual_environment_name* python=3.11\n",
        "Please confirm you have installed listed packages before you start the workshop:\n",
        "- Python (demo version 3.11.9)\n",
        "- Tensorflow (demo version 2.17.0)\n",
        "- NLTK (demo version 3.9.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cb63ed2",
      "metadata": {
        "id": "1cb63ed2"
      },
      "source": [
        "## 2. A Taste of NLTK on Text Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de225c60",
      "metadata": {
        "id": "de225c60"
      },
      "outputs": [],
      "source": [
        "# Import NLTK package\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64e265f0",
      "metadata": {
        "id": "64e265f0"
      },
      "outputs": [],
      "source": [
        "# Create a sample utterance 1 (utt1)\n",
        "utt1 = \"On every weekend, early in the morning. I drive my car to the car center for car washing. Like clock-work.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6753e3ac",
      "metadata": {
        "id": "6753e3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9d57b146-3b66-4a27-bb55-b881473a5401"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'On every weekend, early in the morning. I drive my car to the car center for car washing. Like clock-work.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Display utterance\n",
        "utt1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a942d43-c994-484e-8090-4142060fefd7",
      "metadata": {
        "id": "9a942d43-c994-484e-8090-4142060fefd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81fa8ed-0d56-494e-ce66-56c106085759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "nltk.download('punkt_tab')  # refers to a tokenizer model in the NLTK library,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d6fdf3",
      "metadata": {
        "id": "b3d6fdf3"
      },
      "outputs": [],
      "source": [
        "# Create utterance tokens (utokens)\n",
        "utokens = nltk.word_tokenize(utt1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d7a72e6",
      "metadata": {
        "id": "4d7a72e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d357ca76-22fb-410b-d8ca-8c2ccac68c05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['On',\n",
              " 'every',\n",
              " 'weekend',\n",
              " ',',\n",
              " 'early',\n",
              " 'in',\n",
              " 'the',\n",
              " 'morning',\n",
              " '.',\n",
              " 'I',\n",
              " 'drive',\n",
              " 'my',\n",
              " 'car',\n",
              " 'to',\n",
              " 'the',\n",
              " 'car',\n",
              " 'center',\n",
              " 'for',\n",
              " 'car',\n",
              " 'washing',\n",
              " '.',\n",
              " 'Like',\n",
              " 'clock-work',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Display utokens\n",
        "utokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff5ab004",
      "metadata": {
        "id": "ff5ab004"
      },
      "source": [
        "## 3. How to Install NLTK?\n",
        "#### Type 'pip install nltk'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecef1e80",
      "metadata": {
        "id": "ecef1e80"
      },
      "source": [
        "#### Installing NLTK Data\n",
        "#### Once you finished install NLTK into Python, you can download the NLTK Data\n",
        "#### 3.1 Run Python\n",
        "#### 3.2 Type the following to activate the NLTK downloader.\n",
        "- import nltk\n",
        "- nltk.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86094b3a",
      "metadata": {
        "id": "86094b3a"
      },
      "source": [
        "## 4. Why using Python for NLP?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10699041",
      "metadata": {
        "id": "10699041"
      },
      "source": [
        "Before the popularity of Python in AI and NLP, C, C++ and later on Java dominate the world of software development.\n",
        "However, started from early 2000, Python and their associate toolkit and packages start to dominate the world of software development, especially in the areas of Data Science, AI and NLP.\n",
        "\n",
        "Several reasons to drive for the changes:\n",
        "1. Python is a generalist language, means that it does not specialize in one area.\n",
        "2. Other commonly used language such as Java and JavaScript, on the other hand, is specifically designed for use on the web, thet are most suitable for developing web applications and websites.\n",
        "3. Python, on the other hand, is a generalist language, which means it can be used for a wide variety of purposes, including:\n",
        "- Data Science Analysis and Applications\n",
        "- Developing web apps\n",
        "- Creating software (both Web or Non-web based)\n",
        "- AI modeling and applications (e.g. building Deep Networks)\n",
        "- Natural language processing\n",
        "4. Easy to learn and use. As compared with C and C++, Python is much easier to learn. Especially useful for non-computer science students and scientists.\n",
        "5. In term of NLP, Python's list and list-processing data-type provide an excellent environment for the NLP modeling.\n",
        "\n",
        "The following simple Python program shows how Python handle text as list objects, itself already an excellent tokenization tool in NLP!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b36735d",
      "metadata": {
        "id": "6b36735d"
      },
      "outputs": [],
      "source": [
        "# Define utterance 2 (utt2)\n",
        "utt2 = \"Hello world. How are you?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "784e55fa",
      "metadata": {
        "id": "784e55fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d233fca-daa3-49c8-bea7-db9c3e028d7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'world.', 'How', 'are', 'you?']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Using split() method to split it into word tokens\n",
        "utt2.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "904469f8",
      "metadata": {
        "id": "904469f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf54282-5e65-47f7-d9aa-ba20284060f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Hello world. How are you?' contains  5  words.\n"
          ]
        }
      ],
      "source": [
        "# Check the no of word tokens\n",
        "nwords = len(utt2.split())\n",
        "print (\"'Hello world. How are you?' contains \",nwords,\" words.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2e744f8",
      "metadata": {
        "id": "a2e744f8"
      },
      "source": [
        "## 5. NLTK with Basic Text Processing in NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1984d234",
      "metadata": {
        "id": "1984d234"
      },
      "source": [
        "As said, one important feature NLTK is the provision of simple Python tools and methods for us to learn and practise NLP technology, which started by Basic Text Processing in NLP.\n",
        "They include:\n",
        "1. Basic text processing as lists of words.\n",
        "2. Basic statistics on text processing in NLP.\n",
        "3. Simple text analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e52717fc",
      "metadata": {
        "id": "e52717fc"
      },
      "source": [
        "Before we start, of course we need to use some text document to start with.\n",
        "Just like Project Gutenburg word counting we have just learnt, nothing is more straight forward than start with analyzing the classics literature such as Moby Dick.\n",
        "However, in terms of NLP, it is even much better if we can study the text analysis of a variety of document types, such as classics, news and articles and even public speeches.\n",
        "Why? ....\n",
        "So in NLTK, it provides NINE typical text documents for us to start with. It contains: classic literatures, bible texts, famous public speeches, news and articles, and personal corpus.\n",
        "So, let's start ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0cd6627-e268-48a0-a60d-2c5daf126d04",
      "metadata": {
        "id": "a0cd6627-e268-48a0-a60d-2c5daf126d04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0230e7d9-9cb4-4363-8c68-2cd813d38be7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "nltk.download('gutenberg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ce6a59-2487-4cf4-867d-5ef0935486f8",
      "metadata": {
        "id": "38ce6a59-2487-4cf4-867d-5ef0935486f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6298184e-7807-4574-9c5d-11c5c3bafe3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/genesis.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "nltk.download('genesis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5cf570b-534e-46f7-bd2a-fb23aa97483e",
      "metadata": {
        "id": "c5cf570b-534e-46f7-bd2a-fb23aa97483e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537228a1-d15d-4508-c13d-1bc00bcc01c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/inaugural.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "nltk.download('inaugural')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d114d905-dead-4bfd-b83c-9d9466b73a83",
      "metadata": {
        "id": "d114d905-dead-4bfd-b83c-9d9466b73a83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15be9b18-07ef-450f-f44d-6c844d1a0b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nps_chat.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "nltk.download('nps_chat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "009ada4d-b25a-4c0a-a170-9d9db2539ce0",
      "metadata": {
        "id": "009ada4d-b25a-4c0a-a170-9d9db2539ce0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72169770-f053-40ad-bda0-377371a2281e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/webtext.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "nltk.download('webtext')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a626baf8-34ed-4b22-8506-bb095685b1fd",
      "metadata": {
        "id": "a626baf8-34ed-4b22-8506-bb095685b1fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec2115b-9ddd-458c-8792-967744c18ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "nltk.download('treebank')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb5604c-9c2e-483c-bae7-f852ac258899",
      "metadata": {
        "id": "6fb5604c-9c2e-483c-bae7-f852ac258899",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e678e39b-ff48-40a5-d7fb-95e1f9666388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ],
      "source": [
        "# Let's load some sample books from NLTK databank\n",
        "import nltk\n",
        "from nltk.book import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03118df2",
      "metadata": {
        "id": "03118df2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62fd77c-1d3e-4d25-d50e-acd2b114ad17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ],
      "source": [
        "# Display the list of sample books\n",
        "texts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af56ff8b",
      "metadata": {
        "id": "af56ff8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aff011e-8b2b-4d36-95f4-87da28b29d88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Text: Moby Dick by Herman Melville 1851>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Check text1\n",
        "text1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bce5066f",
      "metadata": {
        "id": "bce5066f"
      },
      "outputs": [],
      "source": [
        "# Know more about text1, check this\n",
        "text1?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecc2f3c0",
      "metadata": {
        "id": "ecc2f3c0"
      },
      "outputs": [],
      "source": [
        "# Import word_tokenize as wtoken\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Use text1 (Moby Dick) from NLTK book corpus\n",
        "tholmes = text1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96280218",
      "metadata": {
        "id": "96280218"
      },
      "source": [
        "## 6 Simple Text Analysis with NLTK"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e115b04",
      "metadata": {
        "id": "3e115b04"
      },
      "source": [
        "In text analysis, one common operation is to study how a particular word (or phrase) appeared in a text document, especially in a classical and famous literature and text document such as public speeches.\n",
        "Different from normal \"search\" function, \"concordance()\" function allows us to study and analyze how a particular appeared within a text document. In other words, it not only shows the occurence, but more importantly the \"neighbouring words and phrases\" as well.\n",
        "Let's try some example in Adventures Holmes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3da8880",
      "metadata": {
        "id": "f3da8880",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a82d1d-7529-4f5d-c1d0-e08d10f93eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no matches\n"
          ]
        }
      ],
      "source": [
        "# Check concordance of word \"Sherlock \"\n",
        "tholmes.concordance(\"Sherlock\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96ebeaf2",
      "metadata": {
        "id": "96ebeaf2"
      },
      "source": [
        "1. The above example shows all the occurrence of \"Sherlock\" inside the text document, by that we will study when it will be used. As one can see, as \"Sherlock\" is a rather \"special\" word with is strongly linked with the name \"Sherlock Holmes\", so almost all the time \"Sherlock\" and \"Holmes\" will be appeared together.\n",
        "\n",
        "2. However in terms of text analysis and especially for the learning of English from some great literature such as Adventures of Sherlock Holmes. Of course, one important thing we want to know to how some commonly-used words and phrases are used by these great authors and what other words of similar meanings (i.e. Synonyms) are being used to improve the Use of English."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c28b084",
      "metadata": {
        "id": "2c28b084"
      },
      "source": [
        "In the following example, let's study how \"extreme\" is used in Adventures of Sherlock Holmes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76e62c58",
      "metadata": {
        "id": "76e62c58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef33508a-0b4a-4b1c-8205-3c646a15919d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 13 of 13 matches:\n",
            "he streets take you waterward . Its extreme downtown is the battery , where tha\n",
            "ll flourish , must indeed have been extreme . But it was not in reasonable natu\n",
            "ue lurks in these small things when extreme political superstitions invest them\n",
            "hem for the event . It took off the extreme edge of their wonder ; and so what \n",
            "t been descried . Likewise upon the extreme stern of the boat where it was also\n",
            "mes over a man only in some time of extreme tribulation ; it comes in the very \n",
            ", both by night and by day , and so extreme was the hard work they underwent , \n",
            "the leaded chocks or grooves in the extreme pointed prow of the boat , where a \n",
            "re now to consider that only in the extreme , lower , backward sloping part of \n",
            "s . His motions plainly denoted his extreme exhaustion . In most land animals t\n",
            "ntly rocking , jerking boat , under extreme headway . Steel and wood included ,\n",
            "rced his groin ; nor was it without extreme difficulty that the agonizing wound\n",
            "' ll heave .\" They went towards the extreme stern , on the ship ' s lee side , \n"
          ]
        }
      ],
      "source": [
        "# Check concordance of word \"extreme\"\n",
        "tholmes.concordance(\"extreme\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0437dd1b",
      "metadata": {
        "id": "0437dd1b"
      },
      "source": [
        "<img src=\"./note.png\" width = \"\" height = \"\" alt=\"note\" align=left />\n",
        "Note: As one can see, in many dictionaries,we are using concordance technique to learn English, so-called \"Use of English\", which is not only on the grammatic aspect, but rather how different words (or phrases) are being used. As what we now called \"Learn by Examples\".\n",
        "In this example, we learnt how to use the word \"extreme\" in various situations and scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3dc3759",
      "metadata": {
        "id": "c3dc3759",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5bb28cf-3fa6-46db-8dca-53967b27ae23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it long there huge little bound short ishmael nor deck inducements\n",
            "spent outer roughly ahab terrific jagged severest impressive manifold\n"
          ]
        }
      ],
      "source": [
        "tholmes.similar(\"extreme\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c82e26d",
      "metadata": {
        "id": "2c82e26d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7533b983-fd47-4beb-a52a-dd13cc136e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 4 of 4 matches:\n",
            "n another day or two perhaps ; this extreme mildness can hardly last longer -- \n",
            "ng her that he was kept away by the extreme affection for herself , which he co\n",
            " of his brother , and lamenting the extreme GAUCHERIE which he really believed \n",
            "y which had been leading her to the extreme of languid indolence and selfish re\n"
          ]
        }
      ],
      "source": [
        "# Check concordance of word \"extreme\" in text2\n",
        "text2.concordance(\"extreme\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00f5966a",
      "metadata": {
        "id": "00f5966a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889d9709-a84e-4b0d-9f6c-3c3f723413ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "family centre good opinion life death loss house society children\n",
            "attachment wishes interest goodness heart comfort cheerfulness\n",
            "existence marriage son\n"
          ]
        }
      ],
      "source": [
        "# Check similar word \"extreme\" in text2\n",
        "text2.similar(\"extreme\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74705d58",
      "metadata": {
        "id": "74705d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480c6dcb-2a28-4f73-eb88-5d71929c6a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 3 of 3 matches:\n",
            " vigilance no Administration by any extreme of wickedness or folly can very ser\n",
            "ent , and communication between the extreme limits of the country made easier t\n",
            "the politics of petty bickering and extreme partisanship they plainly deplore .\n"
          ]
        }
      ],
      "source": [
        "# Check concordance word \"extreme\" in text4\n",
        "text4.concordance(\"extreme\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "580ae39f",
      "metadata": {
        "id": "580ae39f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "693335dc-2808-4975-f5c8-d50d297e2463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one other just hope motives act people agency system right form loss\n",
            "length knowledge science portion quarter narrowest requisite member\n"
          ]
        }
      ],
      "source": [
        "# Check similar word \"extreme\" in text4\n",
        "text4.similar(\"extreme\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc001206",
      "metadata": {
        "id": "fc001206"
      },
      "source": [
        "As one can see, even a commonly used word \"extreme\" different people have differnt \"style\" of usage.\n",
        "In short, Herman Melville used the word \"extreme\"quite frequently in his literature and each with different style of usage.\n",
        "Jane Austen's usage of \"extreme\" is also very \"colorful\" and \"fruitful\", but not as frequently as Herman Melville.\n",
        "While in the Inaugural Address Corpus, the usage of word \"extreme\" become more \"standard\" and \"rigid\" in some sense."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d668c5a",
      "metadata": {
        "id": "9d668c5a"
      },
      "source": [
        "The common_contexts() method allows you to examine the contexts that are shared by two or more words.\n",
        "\n",
        "Let's take a look on how it works.\n",
        "\n",
        "First, use Micky Dicky as example and try what is the common context for the two words: \"extreme\" and \"huge\".\n",
        "\n",
        "To do so, call the common_contexts() function from object \"tholmes\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8433e2d",
      "metadata": {
        "id": "a8433e2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fedffc15-8580-4310-c668-4b3bf9087c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the_lower\n"
          ]
        }
      ],
      "source": [
        "# Check common contexts on tholmes\n",
        "tholmes.common_contexts([\"extreme\",\"huge\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4700a8be",
      "metadata": {
        "id": "4700a8be"
      },
      "source": [
        "What it meant is that: After analysing the two words \"extreme\" and \"huge\", it find out that the common context(s) for the usage of these two words is the \"pattern\" of: the_lower.\n",
        "\n",
        "To check it, what you can do is to call concordance() function for these two words and check against the patterns it extracted. As below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f136663",
      "metadata": {
        "id": "5f136663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b714e00c-1824-4478-e5e4-45628834e88b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 13 of 13 matches:\n",
            "he streets take you waterward . Its extreme downtown is the battery , where tha\n",
            "ll flourish , must indeed have been extreme . But it was not in reasonable natu\n",
            "ue lurks in these small things when extreme political superstitions invest them\n",
            "hem for the event . It took off the extreme edge of their wonder ; and so what \n",
            "t been descried . Likewise upon the extreme stern of the boat where it was also\n",
            "mes over a man only in some time of extreme tribulation ; it comes in the very \n",
            ", both by night and by day , and so extreme was the hard work they underwent , \n",
            "the leaded chocks or grooves in the extreme pointed prow of the boat , where a \n",
            "re now to consider that only in the extreme , lower , backward sloping part of \n",
            "s . His motions plainly denoted his extreme exhaustion . In most land animals t\n",
            "ntly rocking , jerking boat , under extreme headway . Steel and wood included ,\n",
            "rced his groin ; nor was it without extreme difficulty that the agonizing wound\n",
            "' ll heave .\" They went towards the extreme stern , on the ship ' s lee side , \n"
          ]
        }
      ],
      "source": [
        "# Check concordance word \"extreme\" in tholmes\n",
        "tholmes.concordance(\"extreme\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f4a3dda",
      "metadata": {
        "id": "7f4a3dda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b341af1-0024-4790-d2b9-1c344d412051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 25 of 30 matches:\n",
            "close behind some promontory lie The huge Leviathan to attend their prey , And\n",
            ". HARRIS COLL . \" Here they saw such huge troops of whales , that they were fo\n",
            " mummies of those creatures in their huge bake - houses the pyramids . No , wh\n",
            "being , it seems , for some reason a huge favourite with them , they raised a \n",
            "chbowl ;-- taking it I suppose for a huge finger - glass . \" Now ,\" said Queeq\n",
            "glittering in the clear , cold air . Huge hills and mountains of casks on cask\n",
            "feet high ; consisting of the long , huge slabs of limber black bone taken fro\n",
            " rising solemnly and fumbling in the huge pockets of his broad - skirted drab \n",
            "d like the white ivory tusks of some huge elephant , vast curving icicles depe\n",
            "inctly recognised a peculiar sort of huge mole under the whale ' s eye , which\n",
            "e thick mists were dimly parted by a huge , vague form . Affrighted , we all s\n",
            "ng ,\" make out one whit better . The huge corpulence of that Hogarthian monste\n",
            "r on their backs as they scooped out huge globular pieces of the whale of the \n",
            "to dip their ship - biscuit into the huge oil - pots and let them fry there aw\n",
            " thought the whole round sea was one huge cheese , and those sharks the maggot\n",
            " conducted to the windlass , and the huge lower block of the tackles was swung\n",
            " take the head for the trunk of some huge oak , with a bird ' s nest in its cr\n",
            "k at that hanging lower lip ! what a huge sulk and pout is there ! a sulk and \n",
            "ere any of those blinds of bone ; no huge lower lip ; and scarcely anything of\n",
            "nd many fathoms in the rear , swam a huge , humped old bull , which by his com\n",
            "he wounded whale must have been such huge phantoms flitting over his head ! \" \n",
            "iece was carved in the likeness of a huge drooping stalk , was painted green ,\n",
            "he wondrous cistern in the whale ' s huge head ; not the prodigy of his unhing\n",
            " the whale - ship ' s stokers . With huge pronged poles they pitched hissing m\n",
            "neers wildly gesticulated with their huge pronged forks and dippers ; as the w\n"
          ]
        }
      ],
      "source": [
        "# Check concordance word \"huge\" in tholmes\n",
        "tholmes.concordance(\"huge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae47abea",
      "metadata": {
        "id": "ae47abea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "789e5c69-770b-4d57-9516-93f5da211194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "said unto; pray thee; thou shalt; thou hast; thy seed; years old;\n",
            "spake unto; thou art; LORD God; every living; God hath; begat sons;\n",
            "seven years; shalt thou; little ones; living creature; creeping thing;\n",
            "savoury meat; thirty years; every beast\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "text3.collocations()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311403b3",
      "metadata": {
        "id": "311403b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b5f119-2659-4186-9478-ec71cf94e92a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; Vice President; American people; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n"
          ]
        }
      ],
      "source": [
        "text4.collocations()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0c2f5c5",
      "metadata": {
        "id": "e0c2f5c5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}